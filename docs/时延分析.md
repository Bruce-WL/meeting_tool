# 会议纪要生成时延分析

## 1. 流水线概览

一次会议纪要生成分为三个阶段，**总耗时 = ASR + Map + Reduce**（约 10+ 分钟常见于较长录音或模型较慢时）：

| 阶段 | 说明 | 调用方式 | 典型耗时（约） |
|------|------|----------|----------------|
| **ASR** | 语音转文字，整段音频一次请求 | 1 次 API 调用 | 1～5 分钟（随音频时长） |
| **Map** | 按 3000 字分块，每块做中间摘要 | N 块 **并行**（Promise.all） | 1～4 分钟（随块数 N） |
| **Reduce** | 把 Map 结果合成为最终 JSON | **3 次并行**（Part1/2/3 同时请求） | 约 1～2 分钟（取最慢一段） |

---

## 2. 时延长的原因（代码依据）

### 2.1 ASR 阶段（`api/services/asrService.ts`）

- 整段音频 base64 后一次性发给 `volc.bigasr.auc_turbo`。
- 时长主要取决于**音频长度**和接口排队/处理速度。
- 例如 45 分钟会议，ASR 常见 2～5 分钟。

### 2.2 Map 阶段（`api/services/llmService.ts`）

- `CHUNK_SIZE = 3000` 字，转写稿按块切分，块数 `N = ceil(转写长度 / 3000)`。
- 例如 30,000 字 → 10 块，每块一次 LLM 调用（`MAP_MODEL_NAME`，默认 `gpt-4o-mini`）。
- 虽然 **并行**（`Promise.all`），但单块仍需 20～60+ 秒，整体 Map 约 1～4 分钟。

### 2.3 Reduce 阶段（已优化为并行）

- **当前实现**：Part 1 / Part 2 / Part 3 通过 `Promise.all` **并行**执行，墙钟时间 ≈ 最慢一段（约 1～2 分钟），不再叠加。
- 此前为串行时，三次大上下文依次调用，合计 3～6+ 分钟，是主要瓶颈；现已改为并行以缩短总耗时。

### 2.4 小结：总时长与瓶颈

- **ASR**：长录音 2～5 分钟，取决于音频长度与接口。
- **Map**：块数多时 1～4 分钟（并行）。
- **Reduce**：并行后约 1～2 分钟（取最慢一段）。

若仍超过 10 分钟，可重点看 ASR 或 Map 的耗时，或检查 Reduce 单段是否过慢。

---

## 3. 案例：请求 d991f3bb-3639-4640-878e-1706f5472f61 时延分析

| 阶段 | 实际耗时 | 说明 |
|------|----------|------|
| **ASR** | **5.5s** | 音频 8.4MB，转写 1655 字，正常。 |
| **Map** | **209s（约 3.5 分钟）** | 仅 1 个 chunk，**单次 LLM 调用**从 14:25:55 到 14:29:24，`durationMs: 209203`。 |
| **Reduce** | 日志未完整 | Part 1 已发起（同样使用 gpt-5-pro），预计单次也需数分钟。 |

结论：**单次通过 Mify API 的 LLM 请求耗时 ~3.5 分钟**，而你在 Mify 控制台单次请求较快 → 很可能是**中转平台对 API 的限流/排队/优先级**导致：

- API 与控制台可能走不同限流桶或并发上限；
- 同一 API Key 在控制台可能享有更高优先级或更短队列；
- 使用 **gpt-5-pro** 等大模型时，API 侧更容易被排队或限速。

要达成「10 分钟会议 → 2～3 分钟出纪要」，需要把**单次 LLM 调用**压到约 30～60 秒内（并控制 ASR + 调用次数）。

---

## 4. Mify 中转平台与 2～3 分钟目标

### 4.1 为何控制台快、API 慢？

- **限流/并发**：API 可能有「每 Key 并发数」或「QPS」限制，请求被排队。
- **优先级**：控制台测试可能与 API 使用不同队列或优先级。
- **模型**：Pro 等大模型在 API 上可能被限速或排队更久。

建议在 Mify 控制台查看：该 Key 的**速率限制**、**并发上限**、是否有「API 与测试环境差异」说明。

### 4.2 达成 2～3 分钟的可操作项

1. **改用更快模型（优先）**  
   当前日志中 Map/Reduce 均为 **gpt-5-pro**（应为 `.env` 中 `MIFY_MAP_MODEL_NAME` / `MIFY_REDUCE_MODEL_NAME` 或默认模型）。  
   - 建议 API 调用时使用 **gpt-4o-mini** 或 **gpt-5-mini**：单次请求通常 20～60s，且更不易触发限流。  
   - 在项目根目录 `.env` 中设置（若未设则代码默认 Map 为 gpt-4o-mini）：
     ```bash
     MIFY_MAP_MODEL_NAME=gpt-4o-mini
     MIFY_REDUCE_MODEL_NAME=gpt-5-mini
     ```
   或使用你在 Mify 上配置的、**在控制台测试时响应就很快**的模型名。

2. **确认 Mify 控制台限制**  
   在 Mify 查看该 Key：  
   - 每秒/每分钟请求数上限；  
   - 最大并发请求数；  
   若 API 与控制台限流策略不同，可考虑升级套餐或使用「API 专用」Key。

3. **控制并发，避免瞬时多请求**  
   当前 Map 多块已并行、Reduce 三路并行，若 Key 并发上限为 1～2，会排队导致墙钟时间≈各请求顺序相加。  
   - 若确认并发受限，可改为 Map 串行或限并发（如 2），总时间可能略增但更稳定；  
   - 或先改用轻量模型，再视情况恢复并行。

4. **10 分钟会议的大致时间预算（目标 2～3 分钟）**  
   - ASR：约 30s～1min  
   - Map：约 1 块（短会）～4 块（长会），若单次 30～60s 且并行，约 30s～1min  
   - Reduce：3 路并行，单次 30～60s → 约 30s～1min  
   - 合计约 **1.5～3 分钟**，前提是单次 LLM 调用在 30～60s 内、且 Mify 不严重排队。

---

## 5. 如何从日志看时延

### 5.1 控制台（后端运行时的 stdout）

任务完成后会打印一行汇总，例如：

```
[Task <taskId>] 时延汇总: ASR=120.5s, Map=85.2s, Reduce P1=95.0s P2=88.1s P3=72.3s, Finalize=-, Total=461.1s
```

- **ASR=**：语音转写耗时。
- **Map=**：所有分块摘要合计耗时（并行，所以是“最慢那块”的时间）。
- **Reduce P1/P2/P3=**：三段并行合成的各自耗时。
- **Total=**：从开始到结束的总时间。

### 5.2 任务日志文件（按任务维度）

- 路径：`<项目根目录>/logs/task_<taskId>.log`（`logs` 目录在首次写日志时创建）。
- 内容：同一任务下 ASR、Map、Reduce 的详细日志（含 `durationMs`、chunk 数等）。
- 任务结束时有一条 `Processing completed (时延汇总)`，其中包含与上面一致的 `summary` 及各阶段 ms 数。

### 5.3 前端 / 轮询接口

- 轮询 `GET /api/meeting/tasks/:id` 返回的 `task.metrics` 包含：
  - `asrDurationMs`、`mapDurationMs`、`reduceDurationsMs.part1/part2/part3`、`finalizeDurationMs`、`totalDurationMs`。
- 前端结果页在「时延与数据」区域展示这些数值（单位 ms）。

### 5.4 使用脚本跑一次并看汇总

```bash
node api/scripts/latency-test.mjs "/path/to/your/audio.m4a"
```

任务结束后脚本会打印 `task.metrics` 的 JSON，并可从控制台看到上述「时延汇总」行（若后端在同一终端运行）。

---

## 6. 优化建议（针对“10+ 分钟”）

1. **Reduce 并行化**  
   已实现：Part1/Part2/Part3 使用 `Promise.all` 并行请求，Reduce 墙钟时间 ≈ 最慢一段。

2. **缩小 Reduce 单次上下文**  
   若 `combinedNotes` 过长，可考虑：
   - 先对 Map 结果再做一次压缩摘要，再用压缩版做 Part1/2/3；或  
   - 按字段拆成更多、更小的子任务，减少单次请求的 token 数。

3. **Map 块大小与模型**  
   - 适当增大 `CHUNK_SIZE`（例如 4000～5000）可减少块数、减少 Map 调用次数，但单块变慢、可能触及上下文上限，需实测。  
   - 使用更快模型（如更小/更快的 MAP 模型）可缩短 Map 阶段。

4. **ASR**  
   主要受录音时长和 ASR 服务能力影响；若同一段音频多次测试都偏慢，可排查网络与 ASR 服务限流/排队。

---

## 7. 相关代码位置

| 内容 | 文件 |
|------|------|
| 流水线编排与 metrics 写入 | `api/routes/meeting.ts`（`processMeeting`） |
| 时延汇总打印 | `api/routes/meeting.ts`（任务完成前 `console.log` + `logger.log`） |
| ASR 单次调用 | `api/services/asrService.ts`（`transcribeAudio`） |
| Map：分块与并行 | `api/services/llmService.ts`（`splitText`、`CHUNK_SIZE`、`Promise.all(chunkPromises)`） |
| Reduce：三部分并行 | `api/services/llmService.ts`（`generatePart`，Part1/2/3 使用 Promise.all 并行） |
| 任务日志写入 | `api/utils/logger.ts`（TaskLogger，写 `logs/task_<taskId>.log`） |

下次再出现 10+ 分钟时，可直接查看控制台的「时延汇总」或 `logs/task_<taskId>.log` 中的同一汇总，先确认是 ASR、Map 还是 Reduce 占大头，再按上面建议针对性优化。
